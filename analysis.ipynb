{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5363d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d7a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e61d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/model_diff_best.tar\")\n",
    "DATA_PATH = Path(\"data/ARC-AGI-2/data/training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5849a935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(CHECKPOINT_PATH, weights_only=False)\n",
    "config, tokenizer = checkpoint[\"config\"], checkpoint[\"tokenizer\"]\n",
    "model = m.GPT(config=config, device=DEVICE).to(DEVICE)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b94a3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(task, test_index, tokenizer):\n",
    "    new_task = {}\n",
    "    new_task[\"context\"] = deepcopy(task[\"train\"])\n",
    "    train = tokenizer.encode(task[\"train\"])\n",
    "    test = tokenizer.encode([task[\"test\"][test_index]])\n",
    "    soi, eoi, soo, eoo = test.index(10), test.index(11), test.index(12), test.index(13)\n",
    "    test_input, solution = test[soi:eoi+1], test[soo+1:eoo+1]\n",
    "    test_input = test_input + [tokenizer.special_tokens[\"start_of_output\"]]\n",
    "    context = train + test_input\n",
    "    new_task[\"context\"].append(test_input)\n",
    "    return context, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1d85a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(\n",
    "    model, context_tensor, solution, gen_len, mask_token, num_iter\n",
    "):\n",
    "    con_len = context_tensor.size(1)\n",
    "    next_tokens = torch.tensor([mask_token] * gen_len, device=\"cuda\").view(1, -1)\n",
    "    context_masked = torch.cat((context_tensor, next_tokens), dim=-1)\n",
    "    context_masked = context_masked[:, -2048:]\n",
    "    for i in range(1, num_iter + 1):\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                logits = model(context_masked)\n",
    "            s = 1 - (i / num_iter)\n",
    "            num_masks = int(gen_len * s)\n",
    "            probs = torch.softmax(logits, dim=-1)[:, con_len:]\n",
    "            top_probs, top_tokens = torch.max(probs, dim=-1)\n",
    "            _, mask_indices = torch.topk(\n",
    "                top_probs, k=num_masks, largest=False, dim=1\n",
    "            )\n",
    "            next_tokens = top_tokens.clone()\n",
    "            next_tokens[:, mask_indices.view(-1)] = mask_token\n",
    "            context_masked = torch.cat((context_tensor, next_tokens), dim=-1)\n",
    "            context_masked = context_masked[:, -2048:]\n",
    "\n",
    "    accuracy = torch.sum(\n",
    "        solution.view(1, -1) == top_tokens[:, : solution.size(0)]\n",
    "    ) / solution.size(0)\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "795dc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 1\n",
    "filelist = os.listdir(DATA_PATH)\n",
    "task_path = DATA_PATH / filelist[index]\n",
    "task = json.loads(task_path.read_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dfd7b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_token = tokenizer.special_tokens[\"mask_token\"]\n",
    "gen_len = 10\n",
    "context, solution = create_context(task, 0, tokenizer)\n",
    "context_tensor = torch.tensor(context, device=\"cuda\").view(1, -1)\n",
    "solution = torch.tensor(solution, device=\"cuda\").view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41cd1e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (930) must match the size of tensor b (0) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcalculate_accuracy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontext_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgen_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 24\u001b[0m, in \u001b[0;36mcalculate_accuracy\u001b[0;34m(model, context_tensor, solution, gen_len, mask_token, num_iter)\u001b[0m\n\u001b[1;32m     20\u001b[0m         next_tokens[:, mask_indices\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)] \u001b[38;5;241m=\u001b[39m mask_token\n\u001b[1;32m     21\u001b[0m         context_masked \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((context_tensor, next_tokens), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m---> 24\u001b[0m     \u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtop_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msolution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m ) \u001b[38;5;241m/\u001b[39m solution\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m accuracy\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (930) must match the size of tensor b (0) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "calculate_accuracy(\n",
    "    model,\n",
    "    context_tensor,\n",
    "    solution,\n",
    "    gen_len,\n",
    "    mask_token,\n",
    "    num_iter=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af3aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 11]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = tokenizer.encode([task[\"test\"][0]])\n",
    "soi, eoi, soo, eoo = test.index(10), test.index(11), test.index(12), test.index(13)\n",
    "test_input, solution = test[soi:eoi+1], test[soo:eoo+1]\n",
    "test_input[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "556d8f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_of_input': 10,\n",
       " 'end_of_input': 11,\n",
       " 'start_of_output': 12,\n",
       " 'end_of_output': 13,\n",
       " 'row_indicator': 14,\n",
       " 'context_indicator': 15,\n",
       " 'mask_token': 16}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93d20c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8b86736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 189,\n",
       "         3: 42,\n",
       "         4: 30,\n",
       "         14: 17,\n",
       "         8: 10,\n",
       "         15: 1,\n",
       "         10: 1,\n",
       "         11: 1,\n",
       "         12: 1,\n",
       "         13: 1})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tc = Counter(test)\n",
    "tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8e9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d70f232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = checkpoint[\"results\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc52d431",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_losses' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplot_losses\u001b[49m(results)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_losses' is not defined"
     ]
    }
   ],
   "source": [
    "plot_losses(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25e7ff2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.21436849447432904,\n",
       "  0.2189096684404649,\n",
       "  0.21017801734618843,\n",
       "  0.23862626820802688,\n",
       "  0.2284164482052438,\n",
       "  0.24584521789569408,\n",
       "  0.22737450523185543,\n",
       "  0.2263147470052354,\n",
       "  0.2353070877667051,\n",
       "  0.21298127432819455,\n",
       "  0.22931468431837856,\n",
       "  0.2515357826091349,\n",
       "  0.197449276142288,\n",
       "  0.22920571574242785,\n",
       "  0.24085723243653775,\n",
       "  0.22511778990039602,\n",
       "  0.23992838334990665,\n",
       "  0.23327979229157791,\n",
       "  0.24409853484481572,\n",
       "  0.2230953457870055],\n",
       " 3840)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"train_losses\"][-20:], len(results[\"train_losses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "803e4b4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3620, 0.12067817151546478),\n",
       " (3640, 0.12050575017929077),\n",
       " (3660, 0.11765394359827042),\n",
       " (3680, 0.11918774247169495),\n",
       " (3700, 0.11804640293121338),\n",
       " (3720, 0.1210043877363205),\n",
       " (3740, 0.11865618824958801),\n",
       " (3760, 0.11785630881786346),\n",
       " (3780, 0.12139032036066055),\n",
       " (3800, 0.12202248722314835),\n",
       " (3820, 0.12273457646369934),\n",
       " (3840, 0.11935696750879288)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"val_losses\"][180:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e56d590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3])[:, None, None, None].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e29f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-diffusion (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
