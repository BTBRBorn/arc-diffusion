{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5363d8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d7a4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import model as m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e61d07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\"\n",
    "CHECKPOINT_PATH = Path(\"checkpoints/model_diff_best.tar\")\n",
    "DATA_PATH = Path(\"data/pretraining\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5849a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(CHECKPOINT_PATH, weights_only=False)\n",
    "config, tokenizer = checkpoint[\"config\"], checkpoint[\"tokenizer\"]\n",
    "model = m.GPT(config=config, device=DEVICE).to(DEVICE)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "mask_token = tokenizer.special_tokens[\"mask_token\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c864691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_of_input': 10,\n",
       " 'end_of_input': 11,\n",
       " 'start_of_output': 12,\n",
       " 'end_of_output': 13,\n",
       " 'row_indicator': 14,\n",
       " 'context_indicator': 15,\n",
       " 'mask_token': 16}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "495e29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_dataloaders import CustomDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b12511d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(model, x, y, mask_token, num_iter):\n",
    "    mask_ids = (x == mask_token).nonzero(as_tuple=True)[1]\n",
    "    nonmask_ids = (x != mask_token).nonzero(as_tuple=True)[1]\n",
    "    gen_len = mask_ids.numel()\n",
    "    x_clone = x.clone()\n",
    "    for i in range(1, num_iter + 1):\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                logits = model(x_clone)\n",
    "            s = 1 - (i / num_iter)\n",
    "            num_masks = int(gen_len * s)\n",
    "            probs = torch.softmax(logits, dim=-1)\n",
    "            top_probs, top_preds = torch.max(probs, dim=-1)\n",
    "            top_probs[:, nonmask_ids] = 1.0\n",
    "            _, remask_ids = torch.topk(top_probs, k=num_masks, largest=False, dim=1)\n",
    "            x_clone[:, mask_ids] = top_preds[:, mask_ids]\n",
    "            x_clone[:, remask_ids.view(-1)] = mask_token\n",
    "            print(f\"Iter {i}:\")\n",
    "            print(\"start_of_input:\", torch.sum(top_preds == 9).item())\n",
    "            print(\"end_of_input:\", torch.sum(top_preds == 10).item())\n",
    "            print(\"start_of_output:\", torch.sum(top_preds == 11).item())\n",
    "            print(\"end_of_output:\", torch.sum(top_preds == 12).item())\n",
    "            print(\"row_indicator:\", torch.sum(top_preds == 13).item())\n",
    "\n",
    "            accuracy = torch.sum(y[:, mask_ids] == top_preds[:, mask_ids]) / y[:, mask_ids].size(1)\n",
    "\n",
    "    return accuracy, top_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea6fa12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_of_input': 9,\n",
       " 'end_of_input': 10,\n",
       " 'start_of_output': 11,\n",
       " 'end_of_output': 12,\n",
       " 'row_indicator': 13,\n",
       " 'context_indicator': 14,\n",
       " 'mask_token': 15}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d754310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = 2048\n",
    "tr_dataset = CustomDataset(\n",
    "    Path(\"data/pretraining\"), block_size, is_train=True, mask_token=mask_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0ea6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataloader = DataLoader(tr_dataset, batch_size=1, shuffle=True)\n",
    "tr_iter = iter(tr_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fa04d07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(tr_iter)\n",
    "x, y = x.to(\"cuda\"), y.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e3d08eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_of_input: 5\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 3\n",
      "row_indicator: 88\n"
     ]
    }
   ],
   "source": [
    "print(\"start_of_input:\", torch.sum(y == 9).item())\n",
    "print(\"end_of_input:\", torch.sum(y == 10).item())\n",
    "print(\"start_of_output:\", torch.sum(y == 11).item())\n",
    "print(\"end_of_output:\", torch.sum(y == 12).item())\n",
    "print(\"row_indicator:\", torch.sum(y == 13).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b08dcfae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1:\n",
      "start_of_input: 3\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 1\n",
      "row_indicator: 69\n",
      "Iter 2:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 62\n",
      "Iter 3:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 63\n",
      "Iter 4:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 61\n",
      "Iter 5:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 2\n",
      "end_of_output: 1\n",
      "row_indicator: 64\n",
      "Iter 6:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 59\n",
      "Iter 7:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 64\n",
      "Iter 8:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 59\n",
      "Iter 9:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 64\n",
      "Iter 10:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 55\n",
      "Iter 11:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 64\n",
      "Iter 12:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 52\n",
      "Iter 13:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 66\n",
      "Iter 14:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 55\n",
      "Iter 15:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 66\n",
      "Iter 16:\n",
      "start_of_input: 2\n",
      "end_of_input: 3\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 52\n",
      "Iter 17:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 65\n",
      "Iter 18:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 54\n",
      "Iter 19:\n",
      "start_of_input: 3\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 3\n",
      "row_indicator: 64\n",
      "Iter 20:\n",
      "start_of_input: 2\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 2\n",
      "row_indicator: 52\n",
      "Iter 21:\n",
      "start_of_input: 4\n",
      "end_of_input: 2\n",
      "start_of_output: 2\n",
      "end_of_output: 3\n",
      "row_indicator: 66\n",
      "Iter 22:\n",
      "start_of_input: 4\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 4\n",
      "row_indicator: 51\n",
      "Iter 23:\n",
      "start_of_input: 4\n",
      "end_of_input: 2\n",
      "start_of_output: 3\n",
      "end_of_output: 3\n",
      "row_indicator: 67\n",
      "Iter 24:\n",
      "start_of_input: 3\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 4\n",
      "row_indicator: 50\n",
      "Iter 25:\n",
      "start_of_input: 3\n",
      "end_of_input: 2\n",
      "start_of_output: 3\n",
      "end_of_output: 3\n",
      "row_indicator: 65\n",
      "Iter 26:\n",
      "start_of_input: 3\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 3\n",
      "row_indicator: 51\n",
      "Iter 27:\n",
      "start_of_input: 5\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 55\n",
      "Iter 28:\n",
      "start_of_input: 6\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 2\n",
      "row_indicator: 50\n",
      "Iter 29:\n",
      "start_of_input: 4\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 3\n",
      "row_indicator: 47\n",
      "Iter 30:\n",
      "start_of_input: 5\n",
      "end_of_input: 3\n",
      "start_of_output: 3\n",
      "end_of_output: 3\n",
      "row_indicator: 43\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(0.8486, device='cuda:0'), 1361, 5)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, answer = calculate_accuracy(model, x, y, mask_token, 30)\n",
    "acc, torch.sum(x == 16).item(), torch.sum(y == 9).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "f32d578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "acbfafe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y: tensor([[ 3,  3,  3,  3, 13,  3,  0,  3,  3,  3,  3,  3,  3,  3,  3,  3]],\n",
      "       device='cuda:0')\n",
      "a: tensor([[ 3,  3,  3,  3,  3,  3,  3,  3,  3,  3, 13,  3,  3,  3,  3,  3]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "window_size = 16\n",
    "step += 1\n",
    "start, end = step*window_size, (step+1)*window_size \n",
    "mask_ids = (x == mask_token).nonzero(as_tuple=True)[1]\n",
    "y_mask, a_mask = y[:, mask_ids], answer[:, mask_ids]\n",
    "print(\"y:\", y_mask[:, start:end])\n",
    "print(\"a:\", a_mask[:, start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "e93cbc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8, 16, 16,  8, 16, 16, 16,  8, 16,  3,  2,  3, 16, 16,  9,  8, 16,\n",
       "          16, 16, 16,  1, 16, 16, 16, 16,  1, 16, 16,  7,  0, 16]],\n",
       "        device='cuda:0'),\n",
       " tensor([[ 7,  8,  7,  7,  8,  7,  7,  2,  8,  3,  3,  2,  3,  0,  0,  9,  8,  8,\n",
       "           0, 13,  7,  1,  1,  1,  1,  1,  1,  1,  1,  7,  0,  3]],\n",
       "        device='cuda:0'))"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, :50], y[:, :50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "4ce47577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         10, 11,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
       "          3,  3,  3,  3]], device='cuda:0')"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, :40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "85158220",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2048])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "554fe0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_of_input': 10,\n",
       " 'end_of_input': 11,\n",
       " 'start_of_output': 12,\n",
       " 'end_of_output': 13,\n",
       " 'row_indicator': 14,\n",
       " 'context_indicator': 15,\n",
       " 'mask_token': 16}"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1ffc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_context(task, test_index, tokenizer):\n",
    "    new_task = {}\n",
    "    new_task[\"context\"] = deepcopy(task[\"train\"])\n",
    "    train = tokenizer.encode(task[\"train\"])\n",
    "    test = tokenizer.encode([task[\"test\"][test_index]])\n",
    "    soi, eoi, soo, eoo = test.index(10), test.index(11), test.index(12), test.index(13)\n",
    "    test_input, solution = test[soi : eoi + 1], test[soo + 1 : eoo + 1]\n",
    "    test_input = test_input + [tokenizer.special_tokens[\"start_of_output\"]]\n",
    "    context = train + test_input\n",
    "    new_task[\"context\"].append(test_input)\n",
    "    return context, solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b05ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_inference(\n",
    "    model, context_tensor, solution, gen_len, mask_token, num_iter\n",
    "):\n",
    "    con_len = context_tensor.size(1)\n",
    "    next_tokens = torch.tensor([mask_token] * gen_len, device=\"cuda\").view(1, -1)\n",
    "    context_masked = torch.cat((context_tensor, next_tokens), dim=-1)\n",
    "    for i in range(1, num_iter + 1):\n",
    "        with torch.inference_mode():\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                logits = model(context_masked)\n",
    "            s = 1 - (i / num_iter)\n",
    "            num_masks = int(gen_len * s)\n",
    "            probs = torch.softmax(logits, dim=-1)[:, con_len:]\n",
    "            top_probs, top_tokens = torch.max(probs, dim=-1)\n",
    "            _, mask_indices = torch.topk(top_probs, k=num_masks, largest=False, dim=1)\n",
    "            next_tokens = top_tokens.clone()\n",
    "            next_tokens[:, mask_indices.view(-1)] = mask_token\n",
    "            context_masked = torch.cat((context_tensor, next_tokens), dim=-1)\n",
    "\n",
    "    accuracy = torch.sum(\n",
    "        solution.view(1, -1) == top_tokens[:, : solution.size(0)]\n",
    "    ) / solution.size(0)\n",
    "\n",
    "    return accuracy, top_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ef0a6ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_of_input': 10,\n",
       " 'end_of_input': 11,\n",
       " 'start_of_output': 12,\n",
       " 'end_of_output': 13,\n",
       " 'row_indicator': 14,\n",
       " 'context_indicator': 15,\n",
       " 'mask_token': 16}"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b42cb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd9c3aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "784c3a73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_of_input': 9,\n",
       " 'end_of_input': 10,\n",
       " 'start_of_output': 11,\n",
       " 'end_of_output': 12,\n",
       " 'row_indicator': 13,\n",
       " 'context_indicator': 14,\n",
       " 'mask_token': 15}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.special_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f1ab5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\"input\": [[1,2,3], [4, 5, 6], [1, 1, 1]], \"output\": [[7,8,9], [7,7,6]]},\n",
    "        {\"input\": [[1,2,3], [4, 9, 6], [1, 3, 1]], \"output\": [[2,8,9], [7,7,6]]},]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "95410ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14,  9,  1,  2,  3, 13,  4,  5,  6, 13,  1,  1,  1, 10, 11,  7,  8,  9,\n",
       "        13,  7,  7,  6, 12,  9,  1,  2,  3, 13,  4,  9,  6, 13,  1,  3,  1, 10,\n",
       "        11,  2,  8,  9, 13,  7,  7,  6, 12])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(tokenizer.encode(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89066b46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arc-diffusion (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
